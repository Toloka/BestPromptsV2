python language-modeling/run_clm.py --model_name_or_path gpt2-large --train_file train_strings_2.txt --validation_file val_strings_2.txt --per_device_train_batch_size 4 --per_device_eval_batch_size 4 --learning_rate 0.00002294 --preprocessing_num_workers 4 --do_train --do_eval --logging_dir gpt2-large-finetuned-log --output_dir gpt2-large-finetuned --num_train_epochs 6 --logging_steps 5 --save_steps 50 --save_total_limit 2 --evaluation_strategy steps --eval_steps 100 --report_to wandb --weight_decay 0.00002092
